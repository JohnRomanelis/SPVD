{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddc041c-9823-48fc-aa74-81af9ff5bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the path so that we can import the necessary modules\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1016363-37ee-4036-84ca-514bea20c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# imports\n",
    "import torch\n",
    "import math\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "from abc import abstractmethod\n",
    "from models.sparse_utils import batch_sparse_quantize_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3b4d31-dbda-457b-89a4-36f90f86f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from utils.visualization import quick_vis_batch\n",
    "vis_batch = partial(quick_vis_batch, x_offset = 8, y_offset=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3802f50c-99b4-4850-b8c9-0c8a17637e68",
   "metadata": {},
   "source": [
    "# Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6e50c4-8c27-40d7-b4f1-76927eff5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ddpm_unet import SPVUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ea7b1c-26bb-40e5-8ad8-8bbbc761562a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SPVUnet(voxel_size=0.1, nfs=(32, 64, 128, 256), num_layers=1, pres=1e-5)\n",
    "model.pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b2c7be-096c-4084-9557-676e304d2a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = '/home/tourloid/Desktop/PhD/Code/SPVD/checkpoints/spvcnn_0.1_32_64_128_256_constant_lr_Dropout_300.pt'\n",
    "ckpt_path = '/home/vvrbeast/Desktop/Giannis/Code/TransformerDiffusion/checkpoints/spvcnn_0.1_32_64_128_256_constant_lr_1900.pt'\n",
    "model.load_state_dict(torch.load(ckpt_path)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2143462-ee8d-4557-805b-66aa74ee0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5866c5-6e58-429a-9bdf-99272ca434cf",
   "metadata": {},
   "source": [
    "# Create Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e5f22c-2817-489d-8e8d-555144bfc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerBase:\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear'):\n",
    "\n",
    "        self.beta_min, self.beta_max, self.n_steps = beta_min, beta_max, n_steps\n",
    "\n",
    "        if mode == 'linear':\n",
    "            self.inds, self.beta, self.alpha, self.alpha_hat = self._linear_scheduling()\n",
    "        else: \n",
    "            raise NotImplementedError\n",
    "        \n",
    "\n",
    "    def _linear_scheduling(self):\n",
    "\n",
    "        inds = torch.arange(self.n_steps)\n",
    "        beta = torch.linspace(self.beta_min, self.beta_max, self.n_steps)\n",
    "        alpha = 1. - beta\n",
    "        alpha_hat = torch.cumprod(alpha, dim=0)\n",
    "        \n",
    "        return inds, beta, alpha, alpha_hat\n",
    "\n",
    "    def get_pc(self, x_t, shape):\n",
    "        # this functions receives x_t as used by the pipeline returns a cpu tensor\n",
    "        return x_t.detach().cpu().reshape(shape)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, bs, n_points=2048, nf=3, emb=None, save_process=False):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model        : neural net for noise prediction\n",
    "                - bs           : number of samples to generate\n",
    "                - n_points     : number of points per point cloud\n",
    "                - nf           : number of features - default 3 for xyz coordinates\n",
    "                - emb          : conditional embedding, if None it will be ignored\n",
    "                - save_process : save the intermediate point clouds of the generation process\n",
    "        \"\"\"\n",
    "        device = next(model.parameters()).device\n",
    "        shape = (bs, n_points, nf)\n",
    "\n",
    "        x_t = self.create_noise(shape, device)\n",
    "        preds = [self.get_pc(x_t, shape)] \n",
    "\n",
    "        for i, t in enumerate(reversed(self.inds)):\n",
    "            x_t = self.sample_step(model, x_t, t, i, emb, shape, device)\n",
    "            if save_process: preds.append(self.get_pc(x_t, shape)) \n",
    "\n",
    "        return preds if save_process else self.get_pc(x_t, shape)\n",
    "\n",
    "\n",
    "    def sample_step(self, model, x_t, t, i, emb, shape, device):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model  : neural net for noise prediction\n",
    "                - x_t    : previous point cloud\n",
    "                - t      : current time step\n",
    "                - i      : denoising iteration\n",
    "                - emb    : conditional embedding, if None it will be ignored\n",
    "                - shape  : shape of the point cloud\n",
    "                - device : device to run the computations\n",
    "        \"\"\"\n",
    "        bs = shape[0]\n",
    "\n",
    "        # creating the time embedding variable\n",
    "        t_batch = torch.full((bs,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        # activate the model to predict the noise\n",
    "        noise_pred = model((x_t, t_batch)) if emb is None else model((x_t, t_batch, emb))\n",
    "        \n",
    "        # calculate the new point coordinates\n",
    "        x_t = self.update_rule(x_t, noise_pred, t, i, shape, device)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "    def create_noise(self, shape, device):\n",
    "        return torch.randn(shape).to(device)\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_x0_from_noise(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update_rule(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def noisify_sample(self, x0, step):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59263a34-2937-4762-a363-880310ff3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseScheduler(SchedulerBase):\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear', pres=1e-5):\n",
    "        super().__init__(beta_min, beta_max, n_steps, mode)\n",
    "        self.pres = pres\n",
    "    \n",
    "    def create_noise(self, shape, device):\n",
    "        noise = torch.randn(shape)\n",
    "        noise = self.torch2sparse(noise, shape).to(device)\n",
    "        return noise\n",
    "\n",
    "    def get_pc(self, x_t, shape):\n",
    "        \n",
    "        # this functions receives x_t as used by the pipeline returns a cpu tensor\n",
    "        return x_t.F.detach().cpu().reshape(shape)\n",
    "\n",
    "    def update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "        # outside the update_rule the point cloud is represented as SparseTensor\n",
    "        x_t = x_t.F\n",
    "        x_t = self._update_rule(x_t, noise_pred, t, i, shape, device)\n",
    "        # return a SparseTensor\n",
    "        return self.torch2sparse(x_t, shape).to(device)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _update_rule(self, x_t, noise_pred, t, shape, device):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    @abstractmethod\n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        # Receive a torch.Tensor of shape BxNxF and returns a SparseTensor representation\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dabadfa-4846-4900-85fd-18ac00893506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseSchedulerCPU(SparseScheduler):\n",
    "\n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        # Receive a torch.Tensor of shape BxNxF and returns a SparseTensor representation\n",
    "        pts = pts.cpu().reshape(shape) # make sure points have the correct shape\n",
    "        \n",
    "        # make coordinates positive\n",
    "        coords = pts[:, :, :3]\n",
    "        coords = coords - coords.min(dim=1, keepdim=True)[0]\n",
    "        coords = coords.numpy()\n",
    "\n",
    "        # Unfortunately we need to loop over the batch to apply sparse_quantize \n",
    "        # Also DATA have to be in CPU and coords represented as np.arrays\n",
    "        batch = []\n",
    "        for b in range(shape[0]):\n",
    "\n",
    "            c, indices = sparse_quantize(coords[b], self.pres, return_index=True)\n",
    "            f = pts[b][indices]\n",
    "\n",
    "            batch.append(\n",
    "                {'pc':SparseTensor(coords = torch.tensor(c), feats=f)}\n",
    "            )\n",
    "        \n",
    "        batch = sparse_collate_fn(batch)['pc']\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4dbb00-31da-4e07-ab81-2b49931bb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler(SparseScheduler):\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, pres=1e-5, mode='linear', sigma='bt'):\n",
    "        super().__init__(beta_min, beta_max, n_steps, mode)\n",
    "        self.pres = pres\n",
    "\n",
    "        assert sigma in ['bt', 'coef_bt'], sigma\n",
    "        if sigma == 'bt':\n",
    "            self.sigma = self.beta.sqrt()\n",
    "        else:\n",
    "            alpha_hat_prev1 = torch.ones_like(self.alpha_hat)\n",
    "            alpha_hat_prev1[1:] = self.alpha_hat[:-1]\n",
    "            self.sigma = torch.sqrt(self.beta * (1 - alpha_hat_prev1) / (1 - self.alpha_hat))\n",
    "    \n",
    "    def _update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "\n",
    "        # create normal noise with the same shape as x_t\n",
    "        z = torch.randn(x_t.shape).to(device)\n",
    "        \n",
    "        # get parameters for the current timestep\n",
    "        a_t, ahat_t, s_t = self.alpha[t], self.alpha_hat[t], self.sigma[t]\n",
    "        \n",
    "        x_t = 1 / math.sqrt(a_t) * (x_t - (1 - a_t) / (math.sqrt(1 - ahat_t)) * noise_pred) + s_t * z\n",
    "\n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04b3edb3-43df-45c8-8518-e3e624e21991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMSparseSchedulerCPU(DDPMScheduler, SparseSchedulerCPU):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e85b3b8-4763-46db-b6a0-284987d16aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = DDPMSparseSchedulerCPU(sigma='coef_bt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6b322e-fb08-48e3-84d3-0263a0c3642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time of 1 sample 28.476323127746582 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "preds = sched.sample(model, 32)\n",
    "t_end = time.time()\n",
    "print(f\"Generation time of {1} sample {t_end-t_start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939a8198-f3b4-44a9-87f8-630f8d88d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5c907-18a1-4ee2-abf8-d55f220c9f72",
   "metadata": {},
   "source": [
    "# Generation on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faeb90c0-4999-47aa-be2b-d03228d1f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseSchedulerGPU(SparseScheduler):\n",
    "\n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        pts = pts.reshape(shape)\n",
    "        \n",
    "        coords = pts[..., :3] # In case points have additional features\n",
    "        coords = coords - coords.min(dim=1, keepdim=True).values\n",
    "        coords, indices = batch_sparse_quantize_torch(coords, voxel_size=self.pres, return_index=True, return_batch_index=False)\n",
    "        feats = pts.view(-1, 3)[indices]\n",
    "\n",
    "        return SparseTensor(coords=coords, feats=feats).to(coords.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df136f5e-00dc-4b7b-815e-08c2df34a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMSparseSchedulerGPU(DDPMScheduler, SparseSchedulerGPU): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "449c4a44-fb19-4a68-a0f9-50a9f213fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = DDPMSparseSchedulerGPU(sigma='coef_bt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f37ec157-8a7f-4519-83bc-d725a3c04a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time of 1 sample 20.02209162712097 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "preds = sched.sample(model, 32)\n",
    "t_end = time.time()\n",
    "print(f\"Generation time of {1} sample {t_end-t_start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c9a3131-5eb6-4083-ae21-f85c0d857976",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00319810-6f99-4dbe-968d-c994fd3d2d2f",
   "metadata": {},
   "source": [
    "# DDIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a8f4a60-eca1-4466-ba9b-583181b220b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIMScheduler(SparseScheduler):\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, pres=1e-5, mode='linear', s_steps=100, s_mode='linear'):\n",
    "        super().__init__(beta_min, beta_max, n_steps, mode)\n",
    "\n",
    "        if s_mode == 'linear':\n",
    "            self.inds = torch.floor(torch.linspace(0, n_steps-1, s_steps + 1)).long()\n",
    "            self.prev_inds = reversed(self.inds[:-1])\n",
    "            self.inds = self.inds[1:]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "\n",
    "        t_1 = self.prev_inds[i]\n",
    "        ahat_t, ahat_t1 = self.alpha_hat[t], self.alpha_hat[t_1]\n",
    "\n",
    "        x_t = math.sqrt(ahat_t1) * ((x_t - math.sqrt(1 - ahat_t) * noise_pred) / math.sqrt(ahat_t)) + (math.sqrt(1 - ahat_t1) * noise_pred)\n",
    "        \n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba7d864f-ad23-478f-bdea-decfb92e2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIMSparseSchedulerCPU(DDIMScheduler, SparseSchedulerCPU): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ed2d46f-6b9b-47c1-8c33-8aeea5611e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time of 1 sample 2.8272712230682373 sec\n"
     ]
    }
   ],
   "source": [
    "sched = DDIMSparseSchedulerCPU(s_steps=100)\n",
    "t_start = time.time()\n",
    "preds = sched.sample(model, 32)\n",
    "t_end = time.time()\n",
    "print(f\"Generation time of {1} sample {t_end-t_start} sec\")\n",
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0ac5c8-b80c-48c5-bf8d-330ff3304642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIMSparseSchedulerGPU(DDIMScheduler, SparseSchedulerCPU): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ea16b95-b6b9-469c-bc8c-b3ea880d4158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time of 1 sample 2.6720387935638428 sec\n"
     ]
    }
   ],
   "source": [
    "sched = DDIMSparseSchedulerGPU(s_steps=100)\n",
    "t_start = time.time()\n",
    "preds = sched.sample(model, 32)\n",
    "t_end = time.time()\n",
    "print(f\"Generation time of {1} sample {t_end-t_start} sec\")\n",
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7667fc-f938-4b73-b728-2c2773ed9673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa82f82e-4e66-4429-b910-9a877b4d4491",
   "metadata": {},
   "source": [
    "# REMAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589e4ab-cc9d-475a-91dc-46ae877bdea5",
   "metadata": {},
   "source": [
    "## SCHEDULING STRATEGIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9045438-b00d-466f-b79c-9dfdeeadc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SchedulingStrategy:\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def steps(self):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f657895-9580-4712-ab38-180a85454fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DDPMBase(SchedulingStrategy):\n",
    "    '''\n",
    "    This is a Base method for all conventional schedulers like DDPM and DDIM that interpolate between a beta_min and beta_max value\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear'):\n",
    "        self.beta_min, self.beta_max, self.n_steps = beta_min, beta_max, n_steps\n",
    "\n",
    "        if mode == 'linear':\n",
    "            self.inds, self.beta, self.alpha, self.alpha_hat = self._linear_scheduling()\n",
    "            self.inds = reversed(self.inds)\n",
    "        else: \n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _linear_scheduling(self):\n",
    "\n",
    "        inds = torch.arange(self.n_steps)\n",
    "        beta = torch.linspace(self.beta_min, self.beta_max, self.n_steps)\n",
    "        alpha = 1. - beta\n",
    "        alpha_hat = torch.cumprod(alpha, dim=0)\n",
    "        \n",
    "        return inds, beta, alpha, alpha_hat\n",
    "    \n",
    "    @property\n",
    "    def steps(self):\n",
    "        return self.inds\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2821f594-161f-4d46-aed4-a323d550bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DDPM(DDPMBase):\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear', sigma='bt'):\n",
    "        super().__init__(beta_min, beta_max, n_steps, mode)\n",
    "\n",
    "        # DDPM sigma coef\n",
    "        assert sigma in ['bt', 'coef_bt'], sigma\n",
    "        if sigma == 'bt':\n",
    "            self.sigma = self.beta.sqrt()\n",
    "        else:\n",
    "            alpha_hat_prev1 = torch.ones_like(self.alpha_hat)\n",
    "            alpha_hat_prev1[1:] = self.alpha_hat[:-1]\n",
    "            self.sigma = torch.sqrt(self.beta * (1 - alpha_hat_prev1) / (1 - self.alpha_hat))\n",
    "    \n",
    "    def update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "\n",
    "        # create normal noise with the same shape as x_t\n",
    "        z = torch.randn(x_t.shape).to(device) if t > 0 else torch.zeros(x_t.shape).to(device) \n",
    "                                                       # do not add noise on the last step\n",
    "        \n",
    "        # get parameters for the current timestep\n",
    "        a_t, ahat_t, s_t = self.alpha[t], self.alpha_hat[t], self.sigma[t]\n",
    "        \n",
    "        x_t = 1 / math.sqrt(a_t) * (x_t - (1 - a_t) / (math.sqrt(1 - ahat_t)) * noise_pred) + s_t * z\n",
    "\n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfac4750-98e2-4afa-91ee-ee19144cf1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DDIM(DDPMBase):\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear', s_steps=100, s_mode='linear'):\n",
    "        super().__init__(beta_min, beta_max, n_steps, mode)\n",
    "\n",
    "        if s_mode == 'linear':\n",
    "            self.inds = torch.floor(torch.linspace(0, n_steps-1, s_steps + 1)).long()\n",
    "            self.prev_inds = reversed(self.inds[:-1])\n",
    "            self.inds = reversed(self.inds[1:])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "\n",
    "        t_1 = self.prev_inds[i]\n",
    "        ahat_t, ahat_t1 = self.alpha_hat[t], self.alpha_hat[t_1]\n",
    "\n",
    "        x_t = math.sqrt(ahat_t1) * ((x_t - math.sqrt(1 - ahat_t) * noise_pred) / math.sqrt(ahat_t)) + (math.sqrt(1 - ahat_t1) * noise_pred)\n",
    "        \n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424fe66-787e-468c-b9d9-b97c83edfacf",
   "metadata": {},
   "source": [
    "## Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f65a487c-778b-45a7-9a83-7f6e1b3a0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SchedulerBase:\n",
    "\n",
    "    def __init__(self, strategy:SchedulingStrategy, save_process=False):\n",
    "        self.strategy = strategy\n",
    "        self.save_process = save_process\n",
    "    \n",
    "    def get_pc(self, x_t, shape):\n",
    "        # this functions receives x_t as used by the pipeline returns a cpu tensor\n",
    "        return x_t.detach().cpu().reshape(shape)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, bs, n_points=2048, nf=3, emb=None, save_process=False):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model        : neural net for noise prediction\n",
    "                - bs           : number of samples to generate\n",
    "                - n_points     : number of points per point cloud\n",
    "                - nf           : number of features - default 3 for xyz coordinates\n",
    "                - emb          : conditional embedding, if None it will be ignored\n",
    "                - save_process : save the intermediate point clouds of the generation process\n",
    "        \"\"\"\n",
    "        device = next(model.parameters()).device\n",
    "        shape = (bs, n_points, nf)\n",
    "\n",
    "        x_t = self.create_noise(shape, device)\n",
    "        preds = [self.get_pc(x_t, shape)] \n",
    "\n",
    "        for i, t in enumerate(self.strategy.steps):\n",
    "            x_t = self.sample_step(model, x_t, t, i, emb, shape, device)\n",
    "            if save_process: preds.append(self.get_pc(x_t, shape)) \n",
    "\n",
    "        return preds if save_process else self.get_pc(x_t, shape)\n",
    "\n",
    "\n",
    "    def sample_step(self, model, x_t, t, i, emb, shape, device):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model  : neural net for noise prediction\n",
    "                - x_t    : previous point cloud\n",
    "                - t      : current time step\n",
    "                - i      : denoising iteration\n",
    "                - emb    : conditional embedding, if None it will be ignored\n",
    "                - shape  : shape of the point cloud\n",
    "                - device : device to run the computations\n",
    "        \"\"\"\n",
    "        bs = shape[0]\n",
    "\n",
    "        # creating the time embedding variable\n",
    "        t_batch = torch.full((bs,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        # activate the model to predict the noise\n",
    "        noise_pred = model((x_t, t_batch)) if emb is None else model((x_t, t_batch, emb))\n",
    "        \n",
    "        # calculate the new point coordinates\n",
    "        x_t = self.update_rule(x_t, noise_pred, t, i, shape, device)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "    def create_noise(self, shape, device):\n",
    "        return torch.randn(shape).to(device)\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_x0_from_noise(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update_rule(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def noisify_sample(self, x0, step):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df6ce5f2-e79b-44b9-b466-fc3f8e4e5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SparseScheduler(SchedulerBase):\n",
    "\n",
    "    def __init__(self, strategy:SchedulingStrategy, save_process=False, pres=1e-5):\n",
    "        super().__init__(strategy, save_process)\n",
    "        self.pres = pres\n",
    "    \n",
    "    def create_noise(self, shape, device):\n",
    "        noise = torch.randn(shape)\n",
    "        noise = torch.clamp(noise, min=-3, max=3) # clamping the noise in [-3, 3] cube to reduce outlier points\n",
    "        noise = self.torch2sparse(noise, shape).to(device)\n",
    "        return noise\n",
    "\n",
    "    def get_pc(self, x_t, shape):\n",
    "        # this functions receives x_t as used by the pipeline returns a cpu tensor\n",
    "        return x_t.F.detach().cpu().reshape(shape)\n",
    "\n",
    "    def update_rule(self, x_t, noise_pred, t, i, shape, device):\n",
    "        # outside the update_rule the point cloud is represented as SparseTensor\n",
    "        x_t = x_t.F\n",
    "        x_t = self.strategy.update_rule(x_t, noise_pred, t, i, shape, device)\n",
    "        # return a SparseTensor\n",
    "        return self.torch2sparse(x_t, shape).to(device)\n",
    "\n",
    "        \n",
    "    @abstractmethod\n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        # Receive a torch.Tensor of shape BxNxF and returns a SparseTensor representation\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ac79e0d-62f9-4748-8e88-662563a48ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SparseSchedulerCPU(SparseScheduler):\n",
    "\n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        # Receive a torch.Tensor of shape BxNxF and returns a SparseTensor representation\n",
    "        pts = pts.cpu().reshape(shape) # make sure points have the correct shape\n",
    "        \n",
    "        # make coordinates positive\n",
    "        coords = pts[:, :, :3]\n",
    "        coords = coords - coords.min(dim=1, keepdim=True)[0]\n",
    "        coords = coords.numpy()\n",
    "\n",
    "        # Unfortunately we need to loop over the batch to apply sparse_quantize \n",
    "        # Also DATA have to be in CPU and coords represented as np.arrays\n",
    "        batch = []\n",
    "        for b in range(shape[0]):\n",
    "\n",
    "            c, indices = sparse_quantize(coords[b], self.pres, return_index=True)\n",
    "            f = pts[b][indices]\n",
    "\n",
    "            batch.append(\n",
    "                {'pc':SparseTensor(coords = torch.tensor(c), feats=f)}\n",
    "            )\n",
    "        \n",
    "        batch = sparse_collate_fn(batch)['pc']\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "590cccb3-8cc5-483c-b880-2fe2abdccae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SparseSchedulerGPU(SparseScheduler):\n",
    "\n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        pts = pts.reshape(shape)\n",
    "        \n",
    "        coords = pts[..., :3] # In case points have additional features\n",
    "        coords = coords - coords.min(dim=1, keepdim=True).values\n",
    "        coords, indices = batch_sparse_quantize_torch(coords, voxel_size=self.pres, return_index=True, return_batch_index=False)\n",
    "        feats = pts.view(-1, 3)[indices]\n",
    "\n",
    "        return SparseTensor(coords=coords, feats=feats).to(coords.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f68b8d33-21b9-448b-8d43-b177a3cb1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DDPMSparseSchedulerCPU(SparseSchedulerCPU):\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear', sigma='bt', pres=1e-5, save_process=False):\n",
    "        strategy = DDPM(beta_min=beta_min, beta_max=beta_max, n_steps=n_steps, mode=mode, sigma=sigma)\n",
    "        super().__init__(strategy, save_process=save_process, pres=pres)\n",
    "\n",
    "class DDPMSparseSchedulerGPU(SparseSchedulerGPU):\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear', sigma='bt', pres=1e-5, save_process=False):\n",
    "        strategy = DDPM(beta_min=beta_min, beta_max=beta_max, n_steps=n_steps, mode=mode, sigma=sigma)\n",
    "        super().__init__(strategy, save_process=save_process, pres=pres)\n",
    "\n",
    "class DDIMSparseSchedulerCPU(SparseSchedulerCPU):\n",
    "     def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, s_steps=100, s_mode='linear', mode='linear', pres=1e-5, save_process=False):\n",
    "        strategy = DDIM(beta_min=beta_min, beta_max=beta_max, n_steps=n_steps, mode=mode, s_steps=s_steps, s_mode=s_mode)\n",
    "        super().__init__(strategy, save_process=save_process, pres=pres)\n",
    "\n",
    "class DDIMSparseSchedulerGPU(SparseSchedulerGPU):\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, s_steps=100, s_mode='linear', mode='linear', pres=1e-5, save_process=False):\n",
    "        strategy = DDIM(beta_min=beta_min, beta_max=beta_max, n_steps=n_steps, mode=mode, s_steps=s_steps, s_mode=s_mode)\n",
    "        super().__init__(strategy, save_process=save_process, pres=pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d2526ab-d787-4e07-9ac4-2ebaacec3456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time of 1 sample 2.66850209236145 sec\n"
     ]
    }
   ],
   "source": [
    "sched = DDIMSparseSchedulerCPU()\n",
    "t_start = time.time()\n",
    "preds = sched.sample(model, 32)\n",
    "t_end = time.time()\n",
    "print(f\"Generation time of {1} sample {t_end-t_start} sec\")\n",
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7307729-60a1-4fe2-b559-5e9e4369866a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf0ac8-bdbd-41f7-9ad8-5bbaa1277f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf6265-0fee-435f-9193-e55dfbeb1098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
