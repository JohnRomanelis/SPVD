{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddc041c-9823-48fc-aa74-81af9ff5bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the path so that we can import the necessary modules\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1016363-37ee-4036-84ca-514bea20c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# imports\n",
    "import torch\n",
    "import math\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.collate import sparse_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3b4d31-dbda-457b-89a4-36f90f86f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from utils.visualization import quick_vis_batch\n",
    "vis_batch = partial(quick_vis_batch, x_offset = 8, y_offset=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3802f50c-99b4-4850-b8c9-0c8a17637e68",
   "metadata": {},
   "source": [
    "# Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6e50c4-8c27-40d7-b4f1-76927eff5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ddpm_unet import SPVUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ea7b1c-26bb-40e5-8ad8-8bbbc761562a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SPVUnet(voxel_size=0.1, nfs=(32, 64, 128, 256), num_layers=1, pres=1e-5)\n",
    "model.pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b2c7be-096c-4084-9557-676e304d2a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = '/home/tourloid/Desktop/PhD/Code/SPVD/checkpoints/spvcnn_0.1_32_64_128_256_constant_lr_Dropout_300.pt'\n",
    "model.load_state_dict(torch.load(ckpt_path)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2143462-ee8d-4557-805b-66aa74ee0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5866c5-6e58-429a-9bdf-99272ca434cf",
   "metadata": {},
   "source": [
    "# Create Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e5f22c-2817-489d-8e8d-555144bfc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DDPMSchedulerBase:\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear'):\n",
    "\n",
    "        self.beta_min, self.beta_max, self.n_steps = beta_min, beta_max, n_steps\n",
    "\n",
    "        if mode == 'linear':\n",
    "            self.beta, self.alpha, self.alpha_hat = self._linear_scheduling()\n",
    "        else: \n",
    "            raise NotImplementedError\n",
    "        \n",
    "\n",
    "    def _linear_scheduling(self):\n",
    "\n",
    "        beta = torch.linspace(self.beta_min, self.beta_max, self.n_steps)\n",
    "        alpha = 1. - beta\n",
    "        alpha_hat = torch.cumprod(alpha, dim=0)\n",
    "        \n",
    "        return beta, alpha, alpha_hat\n",
    "\n",
    "    def get_pc(self, x_t, shape):\n",
    "        # this functions receives x_t as used by the pipeline returns a cpu tensor\n",
    "        return x_t.detach().cpu().reshape(shape)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, bs, n_points=2048, nf=3, emb=None, save_process=False):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model        : neural net for noise prediction\n",
    "                - bs           : number of samples to generate\n",
    "                - n_points     : number of points per point cloud\n",
    "                - nf           : number of features - default 3 for xyz coordinates\n",
    "                - emb          : conditional embedding, if None it will be ignored\n",
    "                - save_process : save the intermediate point clouds of the generation process\n",
    "        \"\"\"\n",
    "        device = next(model.parameters()).device\n",
    "        shape = (bs, n_points, nf)\n",
    "\n",
    "        x_t = self.create_noise(shape, device)\n",
    "        preds = [self.get_pc(x_t, shape)] \n",
    "\n",
    "        for t in reversed(range(self.n_steps)):\n",
    "            x_t = self.sample_step(model, x_t, t, emb, shape, device)\n",
    "            if save_process: preds.append(self.get_pc(x_t, shape)) \n",
    "\n",
    "        return preds if save_process else self.get_pc(x_t, shape)\n",
    "\n",
    "\n",
    "    def sample_step(self, model, x_t, t, emb, shape, device):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model  : neural net for noise prediction\n",
    "                - x_t    : previous point cloud\n",
    "                - t      : current time step\n",
    "                - emb    : conditional embedding, if None it will be ignored\n",
    "                - shape  : shape of the point cloud\n",
    "                - device : device to run the computations\n",
    "        \"\"\"\n",
    "        bs = shape[0]\n",
    "\n",
    "        # creating the time embedding variable\n",
    "        t_batch = torch.full((bs,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        # activate the model to predict the noise\n",
    "        noise_pred = model((x_t, t_batch)) if emb is None else model((x_t, t_batch, emb))\n",
    "        \n",
    "        # calculate the new point coordinates\n",
    "        x_t = self.update_rule(x_t, noise_pred, t, shape, device)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "    def create_noise(self, shape, device):\n",
    "        return torch.randn(shape).to(device)\n",
    "\n",
    "    def predict_x0_from_noise(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_rule(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def noisify_sample(self, x0, step):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b3edb3-43df-45c8-8518-e3e624e21991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DDPMSparseScheduler(DDPMSchedulerBase):\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, pres=1e-5, mode='linear', sigma='bt'):\n",
    "        super().__init__(beta_min, beta_max, n_steps, mode)\n",
    "        self.pres = pres\n",
    "\n",
    "        assert sigma in ['bt', 'coef_bt'], sigma\n",
    "        if sigma == 'bt':\n",
    "            self.sigma = self.beta.sqrt()\n",
    "        else:\n",
    "            alpha_hat_prev1 = torch.ones_like(self.alpha_hat)\n",
    "            alpha_hat_prev1[1:] = self.alpha_hat[:-1]\n",
    "            self.sigma = torch.sqrt(self.beta * (1 - alpha_hat_prev1) / (1 - self.alpha_hat))\n",
    "        \n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        # Receive a torch.Tensor of shape BxNxF and returns a SparseTensor representation\n",
    "        pts = pts.cpu().reshape(shape) # make sure points have the correct shape\n",
    "        \n",
    "        # make coordinates positive\n",
    "        coords = pts[:, :, :3]\n",
    "        coords = coords - coords.min(dim=1, keepdim=True)[0]\n",
    "        coords = coords.numpy()\n",
    "\n",
    "        # Unfortunately we need to loop over the batch to apply sparse_quantize \n",
    "        # Also DATA have to be in CPU and coords represented as np.arrays\n",
    "        batch = []\n",
    "        for b in range(shape[0]):\n",
    "\n",
    "            c, indices = sparse_quantize(coords[b], self.pres, return_index=True)\n",
    "            f = pts[b][indices]\n",
    "\n",
    "            batch.append(\n",
    "                {'pc':SparseTensor(coords = torch.tensor(c), feats=f)}\n",
    "            )\n",
    "        \n",
    "        batch = sparse_collate_fn(batch)['pc']\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def create_noise(self, shape, device):\n",
    "        noise = torch.randn(shape)\n",
    "        noise = self.torch2sparse(noise, shape).to(device)\n",
    "        return noise\n",
    "\n",
    "    def update_rule(self, x_t, noise_pred, t, shape, device):\n",
    "\n",
    "        # outside the update_rule the point cloud is represented as SparseTensor\n",
    "        x_t = x_t.F\n",
    "\n",
    "        # create normal noise with the same shape as x_t\n",
    "        z = torch.randn(x_t.shape).to(device)\n",
    "        \n",
    "        # get parameters for the current timestep\n",
    "        a_t, ahat_t, s_t = self.alpha[t], self.alpha_hat[t], self.sigma[t]\n",
    "        \n",
    "        x_t = 1 / math.sqrt(a_t) * (x_t - (1 - a_t) / (math.sqrt(1 - ahat_t)) * noise_pred) + s_t * z\n",
    "\n",
    "        # so we should turn it back to a sparse tensor before return\n",
    "        return self.torch2sparse(x_t, shape).to(device)\n",
    "\n",
    "    def get_pc(self, x_t, shape):\n",
    "        # this functions receives x_t as used by the pipeline returns a cpu tensor\n",
    "        return x_t.F.detach().cpu().reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e85b3b8-4763-46db-b6a0-284987d16aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = DDPMSparseScheduler(sigma='coef_bt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6b322e-fb08-48e3-84d3-0263a0c3642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time of 1 sample 50.82420873641968 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "preds = sched.sample(model, 32)\n",
    "t_end = time.time()\n",
    "print(f\"Generation time of {1} sample {t_end-t_start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "939a8198-f3b4-44a9-87f8-630f8d88d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5c907-18a1-4ee2-abf8-d55f220c9f72",
   "metadata": {},
   "source": [
    "# Generation on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faeb90c0-4999-47aa-be2b-d03228d1f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from models.sparse_utils import batch_sparse_quantize_torch\n",
    "\n",
    "class DDPMSparseSchedulerGPU(DDPMSparseScheduler):\n",
    "\n",
    "    def torch2sparse(self, pts:torch.Tensor, shape):\n",
    "        pts = pts.reshape(shape)\n",
    "        \n",
    "        coords = pts[..., :3] # In case points have additional features\n",
    "        coords = coords - coords.min(dim=1, keepdim=True).values\n",
    "        coords, indices = batch_sparse_quantize_torch(coords, voxel_size=self.pres, return_index=True, return_batch_index=False)\n",
    "        feats = pts.view(-1, 3)[indices]\n",
    "\n",
    "        return SparseTensor(coords=coords, feats=feats).to(coords.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449c4a44-fb19-4a68-a0f9-50a9f213fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = DDPMSparseSchedulerGPU(sigma='coef_bt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37ec157-8a7f-4519-83bc-d725a3c04a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time of 1 sample 41.61255359649658 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "preds = sched.sample(model, 32)\n",
    "t_end = time.time()\n",
    "print(f\"Generation time of {1} sample {t_end-t_start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c9a3131-5eb6-4083-ae21-f85c0d857976",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ae365-4db6-47b5-86e4-3cfb0249ac48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
