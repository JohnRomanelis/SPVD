{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86371346-a756-40f0-b956-ffc8161ff1c7",
   "metadata": {},
   "source": [
    "# Low Resolution Generation to Super Resolution\n",
    "\n",
    "In this notebook, we first generate a dataset with low resolution and then use a super resolution network to enhance the point cloud to the desired density. The rationale behind this approach is to produce a dataset with high variability due to the limited resolution of the initial network. This simplifies the task for the super resolution network, which is primarily focused on completing and refining the shapes.\n",
    "\n",
    "Notes\n",
    "The low resolution dataset may sometimes have missing parts in the subsampled shapes. Fortunately, the super resolution network has been exposed to similar examples during its training, which equips it to some degree to handle shape completion. However, the rarity of such cases might lead to less consistent performance. \n",
    "However, the face that the low resolution network may produce objects with missing components indicates a strong adherence to the training distribution it has learned and a high generation variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bc38e-c54c-4a4c-b1f9-3dc620c806fa",
   "metadata": {},
   "source": [
    "## Set up and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cfea8f3-6ebc-4d99-b940-4f1e178befca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tourloid/Desktop/PhD/Code/SPVD\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14585f26-ac59-4a54-8395-c86f203e043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.spvd import SPVUnet\n",
    "from utils.schedulers import DDPMSparseSchedulerGPU\n",
    "from utils.super_resolution_schedulers import DDPMSparseCompletionSchedulerGPU\n",
    "from tqdm import tqdm\n",
    "from test_generation import get_test_loader, evaluate_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af2f8e-76c0-4606-9b84-64927ccc37d6",
   "metadata": {},
   "source": [
    "# Generate the low res dataset\n",
    "\n",
    "The chair category of shapenet consists of 662 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e44da7-9a66-45f0-acb7-0884ef0183d9",
   "metadata": {},
   "source": [
    "## Load the generation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c46949f-a3f1-405d-b7f1-7e13bf89d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model = SPVUnet(point_channels=3, voxel_size=0.1, num_layers=1, pres=1e-5,\n",
    "                 down_blocks = [[(64, 128, 192, 256, 384, 384), (True, True, True, True, False), (None, None, None, 8, 8)]], # only one point skip connection during downsampling\n",
    "                 up_blocks   = [[(384, 384, 256), (True, True), (8, 8), (3, 3)], \n",
    "                                [(256, 192, 128, 64), (True, True, False), (None, None, None), (3, 3, 3)]])\n",
    "gen_model.load_state_dict(torch.load('./checkpoints/chair_low_res_generation.pt')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44090884-a8aa-4514-a0b5-fd0cda57921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = gen_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d29dba-8782-42ef-aca5-246e1be5541a",
   "metadata": {},
   "source": [
    "## Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8766c8ac-b3ee-4511-94e4-474215001906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 21/21 [20:56<00:00, 59.85s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sched = DDPMSparseSchedulerGPU(sigma='coef_bt')\n",
    "samples = []\n",
    "for i in tqdm(range(0, 662, 32)):\n",
    "    bs = min(662-i, 32)\n",
    "    samples.extend(gen_sched.sample(gen_model, bs, n_points=512))\n",
    "\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0427e1-2e89-4d10-80a2-26847ee4566b",
   "metadata": {},
   "source": [
    "# Upsample the low resolution dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9a040-e24a-41d5-ab64-44066e2558f3",
   "metadata": {},
   "source": [
    "## Load the upsampling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "846d42be-8d31-44fa-9d9d-151959fa1fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([662, 512, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.stack(samples).clone()\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8199824-2cf8-4035-917f-1521c55799a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_model = SPVUnet(point_channels=4, \n",
    "                   down_blocks = [[(64, 128, 192, 256, 256), (True, True, True, False), (None, None, None, None)]], # only one point skip connection during downsampling\n",
    "                   up_blocks   = [[(256, 256, 192), (True, True), (None, None), (3, 3)], \n",
    "                                  [(192, 128, 64), (True, False), (None, None), (3, 3)]])\n",
    "up_model.load_state_dict(torch.load('./checkpoints/SuperRes.pt')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1824fb63-ff7b-48b3-b71c-a5000479f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_model = up_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421ff23-4e89-4f86-9109-3208da69731a",
   "metadata": {},
   "source": [
    "## Upsample the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a3986c4-fd4f-48b7-a3f5-2281f7fe24c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 21/21 [32:29<00:00, 92.85s/it]\n"
     ]
    }
   ],
   "source": [
    "up_sched = DDPMSparseCompletionSchedulerGPU(sigma='coef_bt')\n",
    "\n",
    "samples = torch.stack(samples)\n",
    "generated = []\n",
    "for i in tqdm(range(0, 662, 32)):\n",
    "    bs = min(662-i, 32)\n",
    "    pc = samples[i:i+bs]\n",
    "    generated.extend(up_sched.complete(pc, up_model, n_points=2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933db9e4-6ec8-436c-9150-84da04c18227",
   "metadata": {},
   "source": [
    "# Evaluate the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3bea9-a707-492e-b95e-0cd8d6f2512f",
   "metadata": {},
   "source": [
    "## Normalize the models and save ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b15a58e-c4f1-43dc-ab23-39c3e67cb7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n",
      "Total number of data:4612\n",
      "Min number of points: (train)2048 (test)2048\n",
      "(1, 1, 1)\n",
      "Total number of data:662\n",
      "Min number of points: (train)2048 (test)2048\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/tourloid/Desktop/PhD/Data/ShapeNetCore.v2.PC15k\"\n",
    "#path = \"/home/vvrbeast/Desktop/Giannis/Data/ShapeNetCore.v2.PC15k\"\n",
    "\n",
    "test_loader = get_test_loader(path, ['chair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f67e110-3844-4552-b454-db4d3d7f3cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc4ddfd8-0521-4cf0-afdc-f80e9346a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated = torch.stack(generated)\n",
    "all_sample = []\n",
    "all_ref = []\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    bs = min(662-i*32, 32)\n",
    "    m, s = data['mean'].float(), data['std'].float()\n",
    "    out_pc = generated[i:i+bs]\n",
    "    te_pc = data['test_points']\n",
    "\n",
    "    out_pc = out_pc * s + m\n",
    "    te_pc = te_pc * s + m    \n",
    "\n",
    "    all_sample.append(out_pc)\n",
    "    all_ref.append(te_pc)\n",
    "\n",
    "sample_pcs = torch.cat(all_sample, dim=0)\n",
    "ref_pcs = torch.cat(all_ref, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa7603-822c-4667-9655-8f354552b6a1",
   "metadata": {},
   "source": [
    "## Save the generated pcs \n",
    "Save to the *results* folder named as *generated_pcs.npy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51d5d2ae-8241-45b9-ba0b-c355f5484511",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='./results/'\n",
    "np.save(os.path.join(save_path, 'generated_pcs.npy'), sample_pcs.cpu().numpy())\n",
    "np.save(os.path.join(save_path, 'reference_pcs.npy'), ref_pcs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519d486-0d8a-416a-8b0a-95e3d22183af",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fbd7835-11e8-4b6b-9e37-f58cb4afa9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7296) tensor(0.7972)\n",
      "tensor(-0.0038) tensor(0.0006)\n",
      "Comparing 662 generated samples of shape [2048, 3] to 662 original samples of shape [2048, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 662/662 [08:33<00:00,  1.29it/s]\n",
      "100%|█████████████████████████████████████████████████████| 662/662 [08:29<00:00,  1.30it/s]\n",
      "100%|█████████████████████████████████████████████████████| 662/662 [08:29<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-NN-CD-acc': 0.9592145085334778,\n",
      " '1-NN-CD-acc_f': 0.9984894394874573,\n",
      " '1-NN-CD-acc_t': 0.9199395775794983,\n",
      " '1-NN-EMD-acc': 0.9728096723556519,\n",
      " '1-NN-EMD-acc_f': 0.9969788789749146,\n",
      " '1-NN-EMD-acc_t': 0.9486404657363892,\n",
      " 'lgan_cov-CD': 0.06646525859832764,\n",
      " 'lgan_cov-EMD': 0.07401812821626663,\n",
      " 'lgan_mmd-CD': 0.004472191445529461,\n",
      " 'lgan_mmd-EMD': 0.0240921787917614,\n",
      " 'lgan_mmd_smp-CD': 0.002352555049583316,\n",
      " 'lgan_mmd_smp-EMD': 0.017148727551102638}\n",
      "'JSD: 0.08175276744320037'\n"
     ]
    }
   ],
   "source": [
    "evaluate_gen(path, None, None, save_path='./results/', load_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c6a6e-b492-4b22-9757-74b3d4e3e36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
