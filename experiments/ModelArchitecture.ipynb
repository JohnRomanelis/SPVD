{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9010585d-2d41-4a2a-bed6-b6f612c0d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tourloid/Desktop/PhD/Code/SPVD\n"
     ]
    }
   ],
   "source": [
    "# Add the parent directory to the path so that we can import the necessary modules\n",
    "%cd ..\n",
    "#import sys\n",
    "#sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aee33d4-896f-4d00-8dd3-c2e1faefc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# import already implemented blocks\n",
    "from models.modules import TimeEmbeddingBlock, SparseTransformer, SparseAttention\n",
    "from models.utils import lin, timestep_embedding\n",
    "from models.ddpm_unet import saved, unet_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8153a254-7c38-47d7-9db5-3749719cc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# other exports \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from functools import wraps\n",
    "import torchsparse\n",
    "import torchsparse.nn as spnn\n",
    "from utils import model_num_params\n",
    "import fastcore.all as fc\n",
    "from models.sparse_utils import initial_voxelize, voxel_to_point, point_to_voxel, PointTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3f02f7-f486-4cc4-82ca-1bff172ba629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PointBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, ni, nf):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm1d(ni), \n",
    "            nn.SiLU(), \n",
    "            nn.Linear(ni, nf)\n",
    "        )\n",
    "\n",
    "    def forward(self, z1, z):\n",
    "        z1.F = z1.F + self.conv(z.F)\n",
    "        return z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b878b389-90fb-4685-be18-e4ddc320d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class StemBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, ni, nf, ks=3, name='StemConv'):\n",
    "        super().__init__()\n",
    "        self.voxel_conv = nn.Sequential(\n",
    "            spnn.Conv3d(ni, nf, kernel_size=ks), \n",
    "            spnn.BatchNorm(nf), \n",
    "            spnn.SiLU(),\n",
    "            spnn.Conv3d(nf, nf, kernel_size=ks)\n",
    "        )\n",
    "\n",
    "        self.point_conv = PointBlock(ni, nf)\n",
    "\n",
    "        self.msg = '** ' + name + ' ** \\n'\n",
    "        self.msg += ' -- Voxel Branch \\n'\n",
    "        self.msg += f' Conv3d({ni},{nf})'\n",
    "        self.msg += f' - Params: {model_num_params(self.voxel_conv)} \\n'\n",
    "        self.msg += ' -- Point Branch \\n'\n",
    "        self.msg += f' PointBlock({ni},{nf})'\n",
    "        self.msg += f' - Params: {model_num_params(self.point_conv)} \\n'\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "\n",
    "        x = self.voxel_conv(x)\n",
    "\n",
    "        z1 = voxel_to_point(x, z)\n",
    "        # point residual connection\n",
    "        z1 = self.point_conv(z1, z)\n",
    "\n",
    "        # new voxel features\n",
    "        x = point_to_voxel(x, z1)\n",
    "\n",
    "        return x, z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faebb180-c3e0-4325-802d-ab06097be071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from models.ddpm_unet_attn import EmbResBlock\n",
    "\n",
    "# class EmbResBlock(nn.Module):\n",
    "#     def __init__(self, n_emb, ni, nf=None, ks=3, attn_chans=None):\n",
    "#         super().__init__()\n",
    "#         nf = nf or ni\n",
    "\n",
    "#         self.conv1 = unet_conv(ni, nf, ks)\n",
    "#         self.conv2 = unet_conv(nf, nf, ks=1) # WARNING: This should be 3, but I change it to 1 to decrease the number of parameters\n",
    "                                            \n",
    "\n",
    "#         self.t_emb = TimeEmbeddingBlock(n_emb, nf)\n",
    "        \n",
    "#         self.idconv = fc.noop if ni==nf else nn.Linear(ni, nf) \n",
    "\n",
    "#         self.attn = False\n",
    "#         if attn_chans: self.attn = SparseAttention(nf, attn_chans)\n",
    "\n",
    "    \n",
    "#     def forward(self, x_in, t):\n",
    "\n",
    "#         # first conv\n",
    "#         x = self.conv1(x_in)\n",
    "\n",
    "#         # time embedding\n",
    "#         x.F = self.t_emb(x.F, t, x.C[:, 0])\n",
    "\n",
    "#         # second conv\n",
    "#         x = self.conv2(x)\n",
    "\n",
    "#         # residual connection\n",
    "#         x.F = x.F + self.idconv(x_in.F)\n",
    "\n",
    "#         if self.attn: \n",
    "#             x = self.attn(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5937bae-9a88-4a11-9050-572422c7f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, n_emb, ni, nf, add_down=True, num_layers=1, attn_chans=None):\n",
    "        super().__init__()\n",
    "        # v1 - increase dim on first conv\n",
    "        # self.resnets = nn.ModuleList([saved(EmbResBlock(n_emb, ni if i==0 else nf, nf, attn_chans=attn_chans), self)\n",
    "        #                               for i in range(num_layers)])\n",
    "        # self.down = saved(spnn.Conv3d(nf, nf, 2, stride=2),self) if add_down else nn.Identity()\n",
    "\n",
    "        # v2 - increase dim on downsample\n",
    "        self.resnets = nn.ModuleList([saved(EmbResBlock(n_emb, ni, ni, attn_chans=attn_chans), self)\n",
    "                                      for i in range(num_layers)])\n",
    "        self.down = saved(spnn.Conv3d(ni, nf, 2, stride=2),self) if add_down else spnn.Conv3d(ni, nf, 1)#nn.Identity()\n",
    "            \n",
    "    def forward(self, x, t):\n",
    "        self.saved = []\n",
    "        for resnet in self.resnets: x = resnet(x, t)\n",
    "        x = self.down(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b5f26d-067c-4257-9859-9d3827e21940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SPVDownStage(nn.Module):\n",
    "\n",
    "    def __init__(self, n_emb, nfs = (32, 64, 128), add_down=(True, True), num_layers=1, attn_chans=(None, None), name='SPVDownStage'):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        nf = nfs[0]\n",
    "        self.msg = '** ' + name + ' ** \\n'\n",
    "\n",
    "        self.msg += ' -- Voxel Branch \\n'\n",
    "        for i in range(1, len(nfs)):\n",
    "            ni = nf\n",
    "            nf = nfs[i]\n",
    "            self.downs.append(DownBlock(n_emb, ni, nf, add_down=add_down[i-1], num_layers=num_layers,\n",
    "                                        attn_chans=attn_chans[i-1]))\n",
    "            self.msg += f' DownBlock({ni}, {nf}, add_down={add_down[i-1]}, num_layers={num_layers}, attn_chans={attn_chans[i-1]})'\n",
    "            self.msg += f' - Params: {model_num_params(self.downs[-1])} \\n'\n",
    "\n",
    "        self.msg += ' -- Point Branch \\n'\n",
    "        self.point_block = PointBlock(nfs[0], nfs[-1])\n",
    "        self.msg += f' PointBlock({nfs[0]},{nfs[-1]})'\n",
    "        self.msg += f' - Params: {model_num_params(self.point_block)} \\n'\n",
    "\n",
    "    def forward(self, x, z, emb):\n",
    "\n",
    "        self.saved = []\n",
    "\n",
    "        for block in self.downs:\n",
    "            x = block(x, emb)\n",
    "        self.saved += [p for o in self.downs for p in o.saved]\n",
    "\n",
    "        # move to points\n",
    "        z1 = voxel_to_point(x, z)\n",
    "        # point residual connection\n",
    "        z1 = self.point_block(z1, z)\n",
    "\n",
    "        # new voxel features\n",
    "        x = point_to_voxel(x, z1)\n",
    "\n",
    "        return x, z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43fa59e4-d67e-42ed-9abb-7a0085de4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "UpEmbResBlock = EmbResBlock\n",
    "\n",
    "# class UpEmbResBlock(nn.Module):\n",
    "    \n",
    "#     def __init__(self, n_emb, ni, nf=None, ks=3, attn_chans=None):\n",
    "#         super().__init__()\n",
    "#         nf = nf or ni\n",
    "\n",
    "#         self.merge_conv = nn.Sequential(\n",
    "#             nn.BatchNorm1d(ni),\n",
    "#             nn.SiLU(), \n",
    "#             nn.Linear(ni, nf)\n",
    "#         )\n",
    "\n",
    "#         ni = nf\n",
    "#         self.conv1 = unet_conv(ni, nf, ks)\n",
    "#         self.conv2 = unet_conv(nf, nf, ks=1) # WARNING: This should be 3, but I change it to 1 to decrease the number of parameters\n",
    "                                            \n",
    "#         self.t_emb = TimeEmbeddingBlock(n_emb, nf)\n",
    "        \n",
    "#         self.idconv = fc.noop if ni==nf else nn.Linear(ni, nf) \n",
    "\n",
    "#         self.attn = False\n",
    "#         if attn_chans: self.attn = SparseAttention(nf, attn_chans)\n",
    "\n",
    "    \n",
    "#     def forward(self, x_in, t):\n",
    "\n",
    "#         # keep x_in for residual connection\n",
    "#         x = x_in\n",
    "\n",
    "#         # merge conv\n",
    "#         x.F = self.merge_conv(x.F)\n",
    "        \n",
    "#         # first conv\n",
    "#         x = self.conv1(x)\n",
    "\n",
    "#         # time embedding\n",
    "#         x.F = self.t_emb(x.F, t, x.C[:, 0])\n",
    "\n",
    "#         # second conv\n",
    "#         x = self.conv2(x)\n",
    "\n",
    "#         # residual connection\n",
    "#         x.F = x.F + self.idconv(x_in.F)\n",
    "\n",
    "#         if self.attn: \n",
    "#             x = self.attn(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb41273e-a217-4136-a97b-e592d626db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, n_emb, prev_nf, ni, nf, add_up=True, num_layers=1, attn_chans=None, ks=3):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            - prev_nf: previous feature dimension during the upsampling stage\n",
    "            - ni     : input feature dimension of the corresponding downsampling stage\n",
    "            - nf     : output feature dimension of the corresponding downsampling stage (not used)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.resnets = nn.ModuleList(\n",
    "            [UpEmbResBlock(n_emb = n_emb, \n",
    "                           ni = prev_nf + ni, \n",
    "                           nf = prev_nf,\n",
    "                           attn_chans=attn_chans,\n",
    "                           ks=ks)\n",
    "            for i in range(num_layers)])\n",
    "\n",
    "        self.up = spnn.Conv3d(prev_nf, ni, 2, stride=2, transposed=True) if add_up else spnn.Conv3d(prev_nf, ni, 1) #nn.Identity()\n",
    "\n",
    "    def forward(self, x, t, ups):\n",
    "        for resnet in self.resnets: x = resnet(torchsparse.cat([x, ups.pop()]), t)\n",
    "        return self.up(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11a9278-c72a-4e1c-8563-67def4672378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SPVUpStage(nn.Module):\n",
    "    def __init__(self, n_emb, nfs = (128, 64, 32), add_up=(True, True), num_layers=1, attn_chans=(None, None), ks=(3, 3), name='SPVDUpStage'):\n",
    "        super().__init__()\n",
    "        self.msg = '** ' + name + ' ** \\n'\n",
    "        self.msg += ' -- Voxel Branch \\n'\n",
    "        \n",
    "        self.ups = nn.ModuleList()\n",
    "\n",
    "        nf = nfs[0]\n",
    "        prev_nf = nf\n",
    "        for i in range(len(nfs)-1):\n",
    "            nf = nfs[i]\n",
    "            ni = nfs[i+1]\n",
    "            self.ups.append(UpBlock(n_emb, prev_nf, ni, nf, add_up=add_up[i], num_layers=num_layers, attn_chans=attn_chans[i], ks=ks[i]))\n",
    "            self.msg += f' UpBlock({prev_nf}, {ni} | {ni}), add_up={add_up[i]}, num_layers = {num_layers}, attn_chans={attn_chans[i]}'\n",
    "            self.msg += f' - Params: {model_num_params(self.ups[-1])} \\n'\n",
    "            prev_nf = ni\n",
    "\n",
    "        self.msg += ' -- Point Branch \\n'\n",
    "        self.point_block = PointBlock(nfs[0], nfs[-1])\n",
    "        self.msg += f' PointBlock({nfs[0]},{nfs[-1]})'\n",
    "        self.msg += f' - Params: {model_num_params(self.point_block)} \\n'\n",
    "\n",
    "    def forward(self, x, z, emb, saved):\n",
    "\n",
    "        for block in self.ups:\n",
    "            x = block(x, emb, saved)\n",
    "\n",
    "        # move to points\n",
    "        z1 = voxel_to_point(x, z)\n",
    "        # point residual connection\n",
    "        z1 = self.point_block(z1, z)\n",
    "\n",
    "        # new voxel features\n",
    "        x = point_to_voxel(x, z1)\n",
    "\n",
    "        return x, z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3faca2fd-d829-40ae-b88e-d02e3963abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SPVUnetSymmetric(nn.Module):\n",
    "    \"\"\"\n",
    "        Definition of a DownBlock:\n",
    "        \n",
    "        Convolutions : | 32 -> 64 | 64 -> 128 | 128 -> 192 |\n",
    "        Add down conv: |   True   |   True    |    True    |  (only define for the down stages, the up stages are created automatically)\n",
    "        Attn chans:    |   None   |   None    |    None    |\n",
    "        Kernel size:   |     3    |     3     |      3     |  (only to skip conv blocks during upsampling --> reduce parameters)\n",
    "        Name:        How to call this layer\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, point_channels=3, voxel_size=0.1, \n",
    "                 blocks = [[(32, 64, 128, 192), (True, True, True), (None, None, None), (3, 3, 3)],\n",
    "                           [(192, 192, 256), (True, False), (8, 8), (3, 3)]],\n",
    "                 num_layers=1, pres=1e-5):\n",
    "        super().__init__()\n",
    "        self.pres=pres\n",
    "        self.voxel_size=voxel_size\n",
    "        self.msg = f'Point Resolution: {self.pres} | Voxel Resolution: {self.voxel_size}\\n'\n",
    "\n",
    "        # time embedding\n",
    "        self.n_temb = nf = blocks[0][0][0]\n",
    "        n_emb = nf * 4\n",
    "        self.emb_mlp = nn.Sequential(lin(self.n_temb, n_emb, norm=nn.BatchNorm1d),\n",
    "                                     lin(n_emb, n_emb))\n",
    "        self.msg += f'Time Embedding size - before mlp: {self.n_temb} , -after mlp: {n_emb} \\n'\n",
    "\n",
    "        self.stem_conv = StemBlock(point_channels, blocks[0][0][0])\n",
    "        self.msg += self.stem_conv.msg\n",
    "\n",
    "        add_down_vals = []\n",
    "        self.down_stages = nn.ModuleList()\n",
    "        for i, block_config in enumerate(blocks):\n",
    "            nfs, add_down, attn_chans, _ = block_config\n",
    "            add_down_vals.extend(add_down)\n",
    "            name = f'Down Stage {i}'\n",
    "            self.down_stages.append(SPVDownStage(n_emb, nfs=nfs, add_down=add_down, attn_chans=attn_chans, name=name, num_layers=num_layers))\n",
    "            self.msg += self.down_stages[-1].msg\n",
    "        \n",
    "        self.mid_stages = nn.Identity()\n",
    "\n",
    "        self.up_stages = nn.ModuleList()\n",
    "        b_idx=0\n",
    "        for i, block_config in enumerate(reversed(blocks)):\n",
    "            nfs, _, attn_chans, ks = map(list, map(reversed, map(list, block_config)))\n",
    "            add_up = add_down_vals[b_idx:b_idx+len(attn_chans)]\n",
    "            b_idx = b_idx + len(attn_chans)\n",
    "            name = f'Up Stage {i}'\n",
    "            self.up_stages.append(SPVUpStage(n_emb, nfs=nfs, add_up=add_up, attn_chans=attn_chans, ks=ks, num_layers=num_layers+1, name=name))\n",
    "            self.msg += self.up_stages[-1].msg\n",
    "\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.BatchNorm1d(blocks[0][0][0]),\n",
    "            nn.SiLU(), \n",
    "            nn.Linear(blocks[0][0][0], point_channels, bias=False),\n",
    "        )\n",
    "\n",
    "        self.msg += '** Noise Predictor ** \\n'\n",
    "        self.msg += f' LinearLayer({blocks[0][0][0]}, {point_channels})'\n",
    "        self.msg += f' - Params: {model_num_params(self.out_conv)} \\n'\n",
    "        \n",
    "        self.msg += f'Total Parameters: {model_num_params(self)/1e6:0.1f}M'\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.msg)\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        # Input Processing\n",
    "        x, t = inp\n",
    "        z = PointTensor(x.F, x.C.float()) # CHECK\n",
    "        t = timestep_embedding(t, self.n_temb)\n",
    "        emb = self.emb_mlp(t)\n",
    "\n",
    "        # Initial Voxelization\n",
    "        x0 = initial_voxelize(z, self.pres, self.voxel_size)\n",
    "\n",
    "        # Stem convolution\n",
    "        x, z = self.stem_conv(x0, z)\n",
    "\n",
    "        saved = [x]\n",
    "\n",
    "        for d in self.down_stages:\n",
    "            x, z = d(x, z, emb)\n",
    "            saved += [p for p in d.saved]\n",
    "\n",
    "        #x = self.mid_stages(x, emb)\n",
    "\n",
    "        for u in self.up_stages:\n",
    "            x, z = u(x, z, emb, saved)\n",
    "        \n",
    "        return self.out_conv(z.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea2e8172-02f7-4caa-963e-beb64a1168e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SPVUnet(nn.Module):\n",
    "    \"\"\"\n",
    "        Definition of a DownBlock:\n",
    "        \n",
    "        Convolutions : | 32 -> 64 | 64 -> 128 | 128 -> 192 |\n",
    "        Add down conv: |   True   |   True    |    True    |  \n",
    "        Attn chans:    |   None   |   None    |    None    |\n",
    "        Kernel size:   |     3    |     3     |      3     |  (only to skip conv blocks during upsampling --> reduce parameters)\n",
    "        Name:        How to call this layer\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, point_channels=3, voxel_size=0.1, \n",
    "                 down_blocks = [[(64, 128, 192, 256, 384, 384), (True, True, True, True, False), (None, None, None, 8, 8)]], # only one point skip connection during downsampling\n",
    "                 up_blocks   = [[(384, 384, 256), (True, True), (8, 8), (3, 3)], \n",
    "                                [(256, 192, 128, 64), (True, True, False), (None, None, None), (3, 3, 3)]],\n",
    "                 num_layers=1, pres=1e-5):\n",
    "        super().__init__()\n",
    "        self.pres=pres\n",
    "        self.voxel_size=voxel_size\n",
    "        self.msg = f'Point Resolution: {self.pres} | Voxel Resolution: {self.voxel_size}\\n'\n",
    "\n",
    "        # time embedding\n",
    "        self.n_temb = nf = down_blocks[0][0][0]\n",
    "        n_emb = nf * 4\n",
    "        self.emb_mlp = nn.Sequential(lin(self.n_temb, n_emb, norm=nn.BatchNorm1d),\n",
    "                                     lin(n_emb, n_emb))\n",
    "        self.msg += f'Time Embedding size - before mlp: {self.n_temb} , -after mlp: {n_emb} \\n'\n",
    "\n",
    "        self.stem_conv = StemBlock(point_channels, down_blocks[0][0][0])\n",
    "        self.msg += self.stem_conv.msg\n",
    "\n",
    "        add_down_vals = []\n",
    "        self.down_stages = nn.ModuleList()\n",
    "        for i, block_config in enumerate(down_blocks):\n",
    "            nfs, add_down, attn_chans = block_config\n",
    "            add_down_vals.extend(add_down)\n",
    "            name = f'Down Stage {i}'\n",
    "            self.down_stages.append(SPVDownStage(n_emb, nfs=nfs, add_down=add_down, attn_chans=attn_chans, name=name, num_layers=num_layers))\n",
    "            self.msg += self.down_stages[-1].msg\n",
    "        \n",
    "        self.mid_stages = nn.Identity()\n",
    "\n",
    "        self.up_stages = nn.ModuleList()\n",
    "        for i, block_config in enumerate(up_blocks):\n",
    "            nfs, add_up, attn_chans, ks = block_config\n",
    "            name = f'Up Stage {i}'\n",
    "            self.up_stages.append(SPVUpStage(n_emb, nfs=nfs, add_up=add_up, attn_chans=attn_chans, ks=ks, num_layers=num_layers+1, name=name))\n",
    "            self.msg += self.up_stages[-1].msg\n",
    "\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.BatchNorm1d(up_blocks[-1][0][-1]),\n",
    "            nn.SiLU(), \n",
    "            nn.Linear(up_blocks[-1][0][-1], point_channels, bias=False),\n",
    "        )\n",
    "\n",
    "        self.msg += '** Noise Predictor ** \\n'\n",
    "        self.msg += f' LinearLayer({up_blocks[-1][0][-1]}, {point_channels})'\n",
    "        self.msg += f' - Params: {model_num_params(self.out_conv)} \\n'\n",
    "        \n",
    "        self.msg += f'Total Parameters: {model_num_params(self)/1e6:0.1f}M'\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.msg)\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        # Input Processing\n",
    "        x, t = inp\n",
    "        z = PointTensor(x.F, x.C.float()) # CHECK\n",
    "        t = timestep_embedding(t, self.n_temb)\n",
    "        emb = self.emb_mlp(t)\n",
    "\n",
    "        # Initial Voxelization\n",
    "        x0 = initial_voxelize(z, self.pres, self.voxel_size)\n",
    "\n",
    "        # Stem convolution\n",
    "        x, z = self.stem_conv(x0, z)\n",
    "\n",
    "        saved = [x]\n",
    "\n",
    "        for d in self.down_stages:\n",
    "            x, z = d(x, z, emb)\n",
    "            saved += [p for p in d.saved]\n",
    "\n",
    "        #x = self.mid_stages(x, emb)\n",
    "\n",
    "        for u in self.up_stages:\n",
    "            x, z = u(x, z, emb, saved)\n",
    "        \n",
    "        return self.out_conv(z.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c4f14db-4d3d-4576-88a9-2efaeb3ab348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point Resolution: 1e-05 | Voxel Resolution: 0.1\n",
      "Time Embedding size - before mlp: 64 , -after mlp: 256 \n",
      "** StemConv ** \n",
      " -- Voxel Branch \n",
      " Conv3d(3,64) - Params: 115904 \n",
      " -- Point Branch \n",
      " PointBlock(3,64) - Params: 262 \n",
      "** Down Stage 0 ** \n",
      " -- Voxel Branch \n",
      " DownBlock(64, 128, add_down=True, num_layers=1, attn_chans=None) - Params: 320000 \n",
      " DownBlock(128, 192, add_down=True, num_layers=1, attn_chans=None) - Params: 1147904 \n",
      " DownBlock(192, 256, add_down=True, num_layers=1, attn_chans=None) - Params: 2483712 \n",
      " DownBlock(256, 384, add_down=True, num_layers=1, attn_chans=8) - Params: 4721408 \n",
      " DownBlock(384, 384, add_down=False, num_layers=1, attn_chans=8) - Params: 8900736 \n",
      " -- Point Branch \n",
      " PointBlock(64,384) - Params: 25088 \n",
      "** Up Stage 0 ** \n",
      " -- Voxel Branch \n",
      " UpBlock(384, 384 | 384), add_up=True, num_layers = 2, attn_chans=8 - Params: 27240960 \n",
      " UpBlock(384, 256 | 256), add_up=True, num_layers = 2, attn_chans=8 - Params: 24094720 \n",
      " -- Point Branch \n",
      " PointBlock(384,256) - Params: 99328 \n",
      "** Up Stage 1 ** \n",
      " -- Voxel Branch \n",
      " UpBlock(256, 192 | 192), add_up=True, num_layers = 2, attn_chans=None - Params: 10622208 \n",
      " UpBlock(192, 128 | 128), add_up=True, num_layers = 2, attn_chans=None - Params: 5828480 \n",
      " UpBlock(128, 64 | 64), add_up=False, num_layers = 2, attn_chans=None - Params: 2402816 \n",
      " -- Point Branch \n",
      " PointBlock(256,64) - Params: 16960 \n",
      "** Noise Predictor ** \n",
      " LinearLayer(64, 3) - Params: 320 \n",
      "Total Parameters: 88.1M\n"
     ]
    }
   ],
   "source": [
    "model = SPVUnet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815e2e4-d152-4527-bf39-8aab33c859bf",
   "metadata": {},
   "source": [
    "# TESTING THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a314eb9-d3b8-4cf4-990b-b072c6b7d84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from datasets.shapenet_pointflow_sparse import ShapeNet15kPointCloudsSparseNoisy\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "import torchsparse\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "from pclab.utils import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14198346-5308-4ea9-af44-5c6d40799361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n",
      "Total number of data:2832\n",
      "Min number of points: (train)2048 (test)2048\n",
      "(1, 1, 1)\n",
      "Total number of data:405\n",
      "Min number of points: (train)2048 (test)2048\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/vvrbeast/Desktop/Giannis/Data/ShapeNetCore.v2.PC15k\"\n",
    "path = \"/home/tourloid/Desktop/PhD/Data/ShapeNetCore.v2.PC15k\"\n",
    "\n",
    "tr_dataset = ShapeNet15kPointCloudsSparseNoisy(\n",
    "            categories= ['airplane'], split='train',\n",
    "            tr_sample_size=2048,\n",
    "            te_sample_size=2048,\n",
    "            scale=1.,\n",
    "            root_dir=path,\n",
    "            normalize_per_shape=False,\n",
    "            normalize_std_per_axis=False, \n",
    "            random_subsample=True)\n",
    "\n",
    "te_dataset = ShapeNet15kPointCloudsSparseNoisy(\n",
    "            categories= ['airplane'], split='val',\n",
    "            tr_sample_size=2048,\n",
    "            te_sample_size=2048,\n",
    "            scale=1.,\n",
    "            root_dir=path,\n",
    "            normalize_per_shape=False,\n",
    "            normalize_std_per_axis=False,\n",
    "            random_subsample=True)\n",
    "\n",
    "tr_dataset.set_voxel_size(1e-5)\n",
    "tr_dataset.set_noise_params(beta_min=1e-5, beta_max=0.008, mode='warm0.1') #beta_max=0.02)\n",
    "\n",
    "te_dataset.set_voxel_size(1e-5)\n",
    "te_dataset.set_noise_params(beta_min=1e-5, beta_max=0.008, mode='warm0.1') #beta_max=0.02)\n",
    "\n",
    "train_dl, valid_dl = map(partial(DataLoader, batch_size=32, shuffle=True, num_workers=8, drop_last=True, collate_fn=sparse_collate_fn), (tr_dataset, te_dataset))\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31956ca7-da77-4fbb-b2e4-1f998b0a1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(valid_dl))\n",
    "pc=batch['input'].F.reshape(32, 2048, 3)\n",
    "vis_batch(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7240b1bd-ae59-4a5e-a8ec-ed6bd8abad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pclab.learner import *\n",
    "from pclab.utils import def_device\n",
    "import fastcore.all as fc\n",
    "from typing import Mapping\n",
    "from copy import copy\n",
    "from torcheval.metrics import Mean\n",
    "from utils.callbacks import GradientClipCB\n",
    "from utils.callbacks import CheckpointCB\n",
    "\n",
    "class DDPMCB(Callback):\n",
    "    \n",
    "    def before_batch(self, learn): \n",
    "        pts = learn.batch['input']\n",
    "        t = torch.tensor(learn.batch['t'])\n",
    "        noise = learn.batch['noise']\n",
    "        inp = (pts, t)\n",
    "        learn.batch = (inp, noise.F)\n",
    "\n",
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, (torch.Tensor, torchsparse.SparseTensor)): return x.to(device)\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k,v in x.items()}\n",
    "    return type(x)(to_device(o, device) for o in x)\n",
    "\n",
    "class DeviceCBSparse(Callback):\n",
    "    order = DDPMCB.order + 1\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)\n",
    "\n",
    "\n",
    "class LossCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): learn.metrics = self\n",
    "    def before_epoch(self, learn): [o.reset() for o in self.all_metrics.values()]\n",
    "\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = learn.batch\n",
    "        #for m in self.metrics.values(): m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b9ef89d-cb10-4d72-a03e-d44d5693bd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddpm_cb = DDPMCB()\n",
    "model = SPVUnet()\n",
    "learn = TrainLearner(model, dls, nn.MSELoss(), cbs=[ddpm_cb, DeviceCBSparse(), GradientClipCB()], opt_func=torch.optim.Adam)\n",
    "learn.lr_find(max_mult=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce3b81f0-7085-4ff9-bb9b-ccfb2f20526e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.397</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.197</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.175</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.168</td>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.164</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.166</td>\n",
       "      <td>2</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.149</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.139</td>\n",
       "      <td>3</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.145</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.146</td>\n",
       "      <td>4</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.145</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.162</td>\n",
       "      <td>5</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.145</td>\n",
       "      <td>6</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>6</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.147</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>7</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.144</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>8</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.139</td>\n",
       "      <td>9</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>9</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.136</td>\n",
       "      <td>10</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>10</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135</td>\n",
       "      <td>11</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>11</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135</td>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.163</td>\n",
       "      <td>12</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135</td>\n",
       "      <td>13</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.133</td>\n",
       "      <td>13</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>14</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.149</td>\n",
       "      <td>14</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>15</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114</td>\n",
       "      <td>16</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>17</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>17</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>18</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>18</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>19</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>19</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.138</td>\n",
       "      <td>20</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>20</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>21</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>21</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>22</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>22</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>23</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>23</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>24</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>24</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.145</td>\n",
       "      <td>25</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>26</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.137</td>\n",
       "      <td>26</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>27</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>27</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>28</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.113</td>\n",
       "      <td>28</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>29</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>29</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.138</td>\n",
       "      <td>30</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>30</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>31</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>31</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>32</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>32</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>33</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114</td>\n",
       "      <td>33</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>34</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>34</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>35</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>36</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>36</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>37</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.103</td>\n",
       "      <td>37</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>38</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>38</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>39</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>39</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>40</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>40</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>41</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>41</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>42</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>42</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>43</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135</td>\n",
       "      <td>43</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>44</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.106</td>\n",
       "      <td>44</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>45</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>45</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>46</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.136</td>\n",
       "      <td>46</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>47</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>47</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>48</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>48</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>49</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>49</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>50</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135</td>\n",
       "      <td>50</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>51</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>51</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>52</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>52</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>53</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>53</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>54</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>54</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>55</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>55</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>56</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>56</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>57</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.109</td>\n",
       "      <td>57</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>58</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.136</td>\n",
       "      <td>58</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>59</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>59</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>60</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.108</td>\n",
       "      <td>60</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>61</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>61</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>62</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.136</td>\n",
       "      <td>62</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>63</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>63</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>64</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>64</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>65</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.142</td>\n",
       "      <td>65</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.132</td>\n",
       "      <td>66</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.109</td>\n",
       "      <td>66</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>67</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>67</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>68</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>68</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>69</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>69</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>70</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>70</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>71</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>71</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>72</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>72</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.115</td>\n",
       "      <td>73</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>73</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>74</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>74</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>75</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>75</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>76</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>76</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>77</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>77</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>78</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>78</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.132</td>\n",
       "      <td>79</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>79</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>80</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>80</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>81</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>81</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>82</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>82</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>83</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>83</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>84</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.136</td>\n",
       "      <td>84</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>85</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.104</td>\n",
       "      <td>85</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>86</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>86</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>87</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>87</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>88</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>88</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>89</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>89</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>90</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>90</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>91</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>91</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>92</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>92</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>93</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.138</td>\n",
       "      <td>93</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>94</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.137</td>\n",
       "      <td>94</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>95</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>95</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>96</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>96</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>97</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>97</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>98</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114</td>\n",
       "      <td>98</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>99</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>99</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>100</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>100</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>101</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>101</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>102</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>102</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>103</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114</td>\n",
       "      <td>103</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>104</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>104</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114</td>\n",
       "      <td>105</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.137</td>\n",
       "      <td>105</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>106</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135</td>\n",
       "      <td>106</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>107</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.112</td>\n",
       "      <td>107</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>108</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>108</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>109</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114</td>\n",
       "      <td>109</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>110</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.115</td>\n",
       "      <td>110</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>111</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.132</td>\n",
       "      <td>111</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>112</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.115</td>\n",
       "      <td>112</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>113</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>113</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>114</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.111</td>\n",
       "      <td>114</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>115</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>115</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>116</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>116</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>117</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>117</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>118</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>118</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.129</td>\n",
       "      <td>119</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.107</td>\n",
       "      <td>119</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>120</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.133</td>\n",
       "      <td>120</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>121</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>121</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>122</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>122</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>123</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.113</td>\n",
       "      <td>123</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>124</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.107</td>\n",
       "      <td>124</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>125</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>125</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>126</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.112</td>\n",
       "      <td>126</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>127</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>127</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>128</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>128</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>129</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>129</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>130</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.132</td>\n",
       "      <td>130</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>131</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>131</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>132</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>132</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>133</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.112</td>\n",
       "      <td>133</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>134</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.151</td>\n",
       "      <td>134</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>135</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>135</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>136</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.109</td>\n",
       "      <td>136</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>137</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.137</td>\n",
       "      <td>137</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>138</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.132</td>\n",
       "      <td>138</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>139</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>139</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>140</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>140</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>141</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>141</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>142</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>142</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>143</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>143</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>144</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.112</td>\n",
       "      <td>144</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>145</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>145</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>146</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>146</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>147</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>147</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>148</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.137</td>\n",
       "      <td>148</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>149</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>149</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>150</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>150</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>151</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>151</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>152</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>152</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>153</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.106</td>\n",
       "      <td>153</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>154</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.134</td>\n",
       "      <td>154</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>155</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>155</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>156</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>156</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>157</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.115</td>\n",
       "      <td>157</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>158</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>158</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>159</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.147</td>\n",
       "      <td>159</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>160</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>160</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>161</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>161</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>162</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130</td>\n",
       "      <td>162</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.131</td>\n",
       "      <td>163</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.110</td>\n",
       "      <td>163</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>164</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>164</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>165</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>165</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>166</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.115</td>\n",
       "      <td>166</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>167</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.114</td>\n",
       "      <td>167</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>168</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>168</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>169</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.112</td>\n",
       "      <td>169</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>170</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.137</td>\n",
       "      <td>170</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>171</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>171</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>172</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.142</td>\n",
       "      <td>172</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>173</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.112</td>\n",
       "      <td>173</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>174</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.102</td>\n",
       "      <td>174</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>175</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128</td>\n",
       "      <td>175</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>176</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>176</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>177</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.124</td>\n",
       "      <td>177</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.119</td>\n",
       "      <td>178</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.109</td>\n",
       "      <td>178</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>179</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.110</td>\n",
       "      <td>179</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>180</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>180</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>181</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.126</td>\n",
       "      <td>181</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>182</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>182</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>183</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.135</td>\n",
       "      <td>183</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>184</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>184</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>185</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>185</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>186</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.137</td>\n",
       "      <td>186</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>187</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127</td>\n",
       "      <td>187</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>188</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>188</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.117</td>\n",
       "      <td>189</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.113</td>\n",
       "      <td>189</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>190</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.113</td>\n",
       "      <td>190</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>191</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>191</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>192</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.139</td>\n",
       "      <td>192</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>193</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>193</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>194</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.133</td>\n",
       "      <td>194</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122</td>\n",
       "      <td>195</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>195</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.121</td>\n",
       "      <td>196</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.125</td>\n",
       "      <td>196</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116</td>\n",
       "      <td>197</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.118</td>\n",
       "      <td>197</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.120</td>\n",
       "      <td>198</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.110</td>\n",
       "      <td>198</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.123</td>\n",
       "      <td>199</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.132</td>\n",
       "      <td>199</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 0.0001 \n",
    "epochs = 200\n",
    "\n",
    "model = SPVUnet()\n",
    "\n",
    "# scheduler\n",
    "total_steps = epochs * len(dls.train)\n",
    "sched = partial(torch.optim.lr_scheduler.OneCycleLR, max_lr=lr, total_steps = total_steps)\n",
    "\n",
    "# Callbacks\n",
    "ddpm_cb = DDPMCB()\n",
    "checkpoint_cb = CheckpointCB(1000, 'airplane', run_params={'msg':model.msg})\n",
    "cbs = [ddpm_cb, DeviceCBSparse(), ProgressCB(plot=False), LossCB(), GradientClipCB(), checkpoint_cb, BatchSchedCB(sched)]\n",
    "\n",
    "learn = TrainLearner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=torch.optim.Adam)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea9511-2d0b-4b40-b26f-1b17526c5020",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9be4236-0957-438d-ad52-e00e7bcdfacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.schedulers import DDPMSparseSchedulerGPU\n",
    "from utils.visualization import quick_vis_batch\n",
    "vis_batch = partial(quick_vis_batch, x_offset = 8, y_offset=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a71f6a29-4b01-49e2-b4c5-832a24dd2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_sched = DDPMSparseSchedulerGPU(n_steps=1000, beta_min=1e-5, beta_max=0.008, pres=1e-5, mode='warm0.1')\n",
    "preds = ddpm_sched.sample(model, 32, 2048)\n",
    "vis_batch(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4c618-888a-4bea-877d-a34a42ae9d9e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b39e34f-a5f6-443f-b776-d8a48aa72493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_generation import evaluate_gen\n",
    "from utils.schedulers import DDPMSparseSchedulerGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6a002-6a3c-400e-b0d8-c50ae0fd9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_sched = DDPMSparseSchedulerGPU(n_steps=1000, beta_min=0.0001, beta_max=0.02, sigma='coef_bt')\n",
    "evaluate_gen(path, model, ddpm_sched, save_path='./results/', cates=['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f5269-d936-4fb5-ac41-eda3ca7de9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_sched = DDPMSparseSchedulerGPU(n_steps=1000, beta_min=0.0001, beta_max=0.02, sigma='coef_bt')\n",
    "evaluate_gen(path, model, ddpm_sched, save_path='./results/', cates=['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aff381-fb0b-49e0-bebc-c03eec0d88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_sched = DDPMSparseSchedulerGPU(n_steps=1000, beta_min=0.0001, beta_max=0.02, sigma='coef_bt')\n",
    "evaluate_gen(path, model, ddpm_sched, save_path='./results/', cates=['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f70bb8-b0c6-4aef-9223-540c2b79edd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
