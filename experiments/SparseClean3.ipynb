{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f7a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the path so that we can import the necessary modules\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b0d5b-126a-4eda-b207-fd98cc1aac12",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbaa3f33-435d-42a3-a432-d081f64500ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'categories': ['chair'],\n",
    "    'train_epochs': 50,\n",
    "    'lr': 0.001,\n",
    "    'load_checkpoint': False, \n",
    "    'save_checkpoint': 'all_depth4',\n",
    "    'save_per_epochs': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb0f6b-3aea-4eec-b80a-456f3b11fadf",
   "metadata": {},
   "source": [
    "# Dataset for Point-Voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4f1c76-7571-4b77-9b50-b21c58343b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "(1, 1, 1)\n",
      "Total number of data:4612\n",
      "Min number of points: (train)2048 (test)2048\n",
      "(1, 1, 1)\n",
      "Total number of data:662\n",
      "Min number of points: (train)2048 (test)2048\n"
     ]
    }
   ],
   "source": [
    "from datasets.shapenet_pointflow_sparse import get_dataloaders\n",
    "from pclab.utils import DataLoaders\n",
    "\n",
    "path = \"/home/tourloid/Desktop/PhD/Data/ShapeNetCore.v2.PC15k\"\n",
    "#path = \"/home/vvrbeast/Desktop/Giannis/Data/ShapeNetCore.v2.PC15k\"\n",
    "train_dl, valid_dl = get_dataloaders(path, args['categories'])\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58852e98-9a16-404a-9538-22f89609a517",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb4c268-27a1-4352-a1d0-0b6bbdedfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from models.modelv1 import SPVUnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054035e2-6833-4823-98ce-be80769175bb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ddb4e-3257-4d4a-a20c-c1103488d121",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e91cae0-db3d-43ea-99c9-f7201669f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pclab.learner import *\n",
    "from pclab.utils import def_device\n",
    "import fastcore.all as fc\n",
    "from typing import Mapping\n",
    "from copy import copy\n",
    "from torcheval.metrics import Mean\n",
    "from utils.callbacks import GradientClipCB\n",
    "from functools import partial\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchsparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375c8a69-cccc-4f65-a971-95c44de65f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMCB(Callback):\n",
    "    \n",
    "    def before_batch(self, learn): \n",
    "        pts = learn.batch['input']\n",
    "        t = torch.tensor(learn.batch['t'])\n",
    "        noise = learn.batch['noise']\n",
    "        inp = (pts, t)\n",
    "        learn.batch = (inp, noise.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8396e050-f0d0-49d1-b83f-442cffc0a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, (torch.Tensor, torchsparse.SparseTensor)): return x.to(device)\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k,v in x.items()}\n",
    "    return type(x)(to_device(o, device) for o in x)\n",
    "\n",
    "class DeviceCBSparse(Callback):\n",
    "    order = DDPMCB.order + 1\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d361ecf-79a9-457c-afc1-9080cd030f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to monitor the loss\n",
    "\n",
    "class LossCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = Mean()\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): learn.metrics = self\n",
    "    def before_epoch(self, learn): [o.reset() for o in self.all_metrics.values()]\n",
    "\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{v.compute():.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "\n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = learn.batch\n",
    "        #for m in self.metrics.values(): m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5fe80-5d05-4703-bbe9-77be39740801",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f818fe-1911-4931-a053-ac9833e15cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model = partial(SPVUnet, voxel_size=0.1, pres=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014c61bf-fc5a-4cc8-89eb-4b4ffae10012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15860739"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import model_num_params\n",
    "model = get_model()\n",
    "model_num_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc11a70-f06b-4a20-afc8-838fe4aeb477",
   "metadata": {},
   "source": [
    "### LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887a33d7-f8b7-4f4f-9699-aa3f1bb5cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_cb = DDPMCB()\n",
    "model = get_model()\n",
    "learn = TrainLearner(model, dls, nn.MSELoss(), cbs=[ddpm_cb, DeviceCBSparse(), GradientClipCB()], opt_func=torch.optim.Adam)\n",
    "#learn.lr_find(max_mult=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111deee8-f710-45d9-ae11-1939d2cc25f0",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8260791-7107-4cdf-9964-6aa0f123b527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6' class='' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [6/15 02:37&lt;03:56]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.558</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.339</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.265</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.267</td>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.262</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.277</td>\n",
       "      <td>2</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.264</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.275</td>\n",
       "      <td>3</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.267</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.270</td>\n",
       "      <td>4</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.260</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.275</td>\n",
       "      <td>5</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='118' class='' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      81.94% [118/144 00:19&lt;00:04 0.224]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m cbs \u001b[38;5;241m=\u001b[39m [ddpm_cb, DeviceCBSparse(), ProgressCB(plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), LossCB(), BatchSchedCB(sched), GradientClipCB()]\n\u001b[1;32m     14\u001b[0m learn \u001b[38;5;241m=\u001b[39m TrainLearner(model, dls, nn\u001b[38;5;241m.\u001b[39mMSELoss(), lr\u001b[38;5;241m=\u001b[39mlr, cbs\u001b[38;5;241m=\u001b[39mcbs, opt_func\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:110\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epochs, train, valid, cbs, lr)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_func: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr)\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m cbs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs\u001b[38;5;241m.\u001b[39mremove(cb)\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:61\u001b[0m, in \u001b[0;36mwith_cbs.__call__.<locals>._f\u001b[0;34m(o, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mException\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:98\u001b[0m, in \u001b[0;36mLearner._fit\u001b[0;34m(self, train, valid)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@with_cbs\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, train, valid):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m train: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m valid: torch\u001b[38;5;241m.\u001b[39mno_grad()(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mone_epoch)(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:93\u001b[0m, in \u001b[0;36mLearner.one_epoch\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mvalid\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:61\u001b[0m, in \u001b[0;36mwith_cbs.__call__.<locals>._f\u001b[0;34m(o, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mException\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:88\u001b[0m, in \u001b[0;36mLearner._one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@with_cbs\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_one_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:61\u001b[0m, in \u001b[0;36mwith_cbs.__call__.<locals>._f\u001b[0;34m(o, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     o\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnm\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mException\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:75\u001b[0m, in \u001b[0;36mLearner._one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@with_cbs\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_predict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss()\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/pclab/pclab/learner.py:125\u001b[0m, in \u001b[0;36mTrainLearner.predict\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/SPVD/experiments/../models/modelv1.py:222\u001b[0m, in \u001b[0;36mSPVUnet.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    219\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_conv3(x3p, emb)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# 5.5 Down Conv 4\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m x4n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_conv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# 6. Third Point Stage\u001b[39;00m\n\u001b[1;32m    225\u001b[0m z3 \u001b[38;5;241m=\u001b[39m voxel_to_point(x4n, z2)\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/SPVD/experiments/../models/modelv1.py:71\u001b[0m, in \u001b[0;36mSimpleDownBlock.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# convolutions\u001b[39;00m\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m---> 71\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sparse/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Dependancies/torchsparse/torchsparse/nn/modules/conv.py:98\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: SparseTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SparseTensor:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransposed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerative\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Dependancies/torchsparse/torchsparse/nn/functional/conv/conv.py:92\u001b[0m, in \u001b[0;36mconv3d\u001b[0;34m(input, weight, kernel_size, bias, stride, padding, dilation, config, transposed, generative, training)\u001b[0m\n\u001b[1;32m     89\u001b[0m spatial_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_range\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kmap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     kmap \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_kernel_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhashmap_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhashmap_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspatial_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownsample_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mifsort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mifsort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_mask_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_mask_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_mask_num_bwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_mask_num_bwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     hashmap \u001b[38;5;241m=\u001b[39m [kmap[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashmap_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m], kmap[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashmap_vals\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39m_caches\u001b[38;5;241m.\u001b[39mkmaps[(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mstride, kernel_size, stride, dilation)] \u001b[38;5;241m=\u001b[39m kmap\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Dependancies/torchsparse/torchsparse/nn/functional/conv/kmap/build_kmap.py:86\u001b[0m, in \u001b[0;36mbuild_kernel_map\u001b[0;34m(_coords, input_node_num, kernel_size, stride, padding, hashmap_keys, hashmap_vals, spatial_range, mode, dataflow, downsample_mode, training, ifsort, generative, split_mask_num, split_mask_num_bwd)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported kmap_mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for generative convolution (please switch to kmap_mode=hashmap).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataflow \u001b[38;5;241m==\u001b[39m Dataflow\u001b[38;5;241m.\u001b[39mImplicitGEMM:\n\u001b[0;32m---> 86\u001b[0m     kmap \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_kmap_implicit_GEMM_hashmap_on_the_fly\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_node_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspatial_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_spatial_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcta_M\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcta_M\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mifsort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mifsort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_mask_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_mask_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataflow \u001b[38;5;241m==\u001b[39m Dataflow\u001b[38;5;241m.\u001b[39mGatherScatter:\n\u001b[1;32m    101\u001b[0m     kmap \u001b[38;5;241m=\u001b[39m build_kmap_Gather_Scatter_hashmap_on_the_fly(\n\u001b[1;32m    102\u001b[0m         kmap,\n\u001b[1;32m    103\u001b[0m         input_node_num,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         subm\u001b[38;5;241m=\u001b[39msubm,\n\u001b[1;32m    111\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/Dependancies/torchsparse/torchsparse/nn/functional/conv/kmap/func/hashmap_on_the_fly.py:72\u001b[0m, in \u001b[0;36mbuild_kmap_implicit_GEMM_hashmap_on_the_fly\u001b[0;34m(kmap, input_node_num, _coords, kernel_size, stride, padding, spatial_range, cta_M, subm, ifsort, split_mask_num)\u001b[0m\n\u001b[1;32m     65\u001b[0m     kmap[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashmap_vals\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m     66\u001b[0m         hashmap_capacity, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32, device\u001b[38;5;241m=\u001b[39mcoords\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     68\u001b[0m hashtable \u001b[38;5;241m=\u001b[39m torchsparse\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mGPUHashTable(\n\u001b[1;32m     69\u001b[0m     kmap[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashmap_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m], kmap[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashmap_vals\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhashtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_insert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# update kernel_map\u001b[39;00m\n\u001b[1;32m     84\u001b[0m out_in_map \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.005\n",
    "epochs = 15 #500 #args['train_epochs'] #400\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# scheduler\n",
    "total_steps = epochs * len(dls.train)\n",
    "sched = partial(torch.optim.lr_scheduler.OneCycleLR, max_lr=lr, total_steps = total_steps)\n",
    "\n",
    "# Callbacks\n",
    "ddpm_cb = DDPMCB()\n",
    "cbs = [ddpm_cb, DeviceCBSparse(), ProgressCB(plot=False), LossCB(), BatchSchedCB(sched), GradientClipCB()]\n",
    "\n",
    "learn = TrainLearner(model, dls, nn.MSELoss(), lr=lr, cbs=cbs, opt_func=torch.optim.Adam)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c45a81-8d26-4d40-80f3-17f01bc25531",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0d60f-c729-4fa4-b1f3-27be838d53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "from utils.visualization import quick_vis_batch\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "vis_batch = partial(quick_vis_batch, x_offset = 8, y_offset=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbbf361-3d52-487e-9b8f-ab854899d2dc",
   "metadata": {},
   "source": [
    "## Noise Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33760aa5-a9d7-4a0d-b3f2-629db6484001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMSchedulerBase:\n",
    "\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, mode='linear'):\n",
    "\n",
    "        self.beta_min, self.beta_max, self.n_steps = beta_min, beta_max, n_steps\n",
    "\n",
    "        if mode == 'linear':\n",
    "            self.beta, self.alpha, self.alpha_hat, self.alpha_hat_prev1 = self._linear_scheduling()\n",
    "        else: \n",
    "            raise NotImplementedError\n",
    "        \n",
    "\n",
    "    def _linear_scheduling(self):\n",
    "\n",
    "        beta = torch.linspace(self.beta_min, self.beta_max, self.n_steps)\n",
    "        alpha = 1. - beta\n",
    "        alpha_hat = torch.cumprod(alpha, dim=0)\n",
    "        alpha_hat_prev1 = torch.ones_like(alpha_hat) # necessary for some scheduling stategies\n",
    "        alpha_hat_prev1[1:] = alpha_hat[:-1] # we want a_hat[0] == 1\n",
    "        \n",
    "        return beta, alpha, alpha_hat, alpha_hat_prev1\n",
    "\n",
    "    def append_prediction(self, preds, x_t):\n",
    "        preds.append(x_t.detach().cpu().numpy())\n",
    "\n",
    "    def create_noise(self, shape, device):\n",
    "        return torch.randn(shape).to(device)\n",
    "    \n",
    "    def sample(self, model, bs, n_points=2048, nf=3, emb=None, save_process=False):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model        : neural net for noise prediction\n",
    "                - shape        : Desired shape of the point cloud BxNxF\n",
    "                - emb          : conditional embedding, if None it will be ignored\n",
    "                - save_process : save the intermediate point clouds of the generation process\n",
    "        \"\"\"\n",
    "        device = next(iter(model.parameters())).device\n",
    "        shape = (bs, n_points, nf)\n",
    "        x_t = self.create_noise(shape, device)\n",
    "\n",
    "        if save_process: \n",
    "            preds = []\n",
    "            self.append_prediction(preds, x_t)\n",
    "\n",
    "        for t in reversed(range(self.n_steps)):\n",
    "            x_t = self.sample_step(model, x_t, t, emb, shape, device)\n",
    "            if save_process: self.append_prediction(preds, x_t)\n",
    "\n",
    "        return preds if save_process else self.append_prediction([], x_t)[0] # In case x_t is not a torch.Tensor\n",
    "\n",
    "\n",
    "    def sample_step(self, model, x_t, t, emb, shape, device):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                - model  : neural net for noise prediction\n",
    "                - x_t    : previous point cloud\n",
    "                - t      : current time step\n",
    "                - emb    : conditional embedding, if None it will be ignored\n",
    "                - shape  : shape of the point cloud\n",
    "                - device : device to run the computations\n",
    "        \"\"\"\n",
    "        bs = shape[0]\n",
    "\n",
    "        # creating the time embedding variable\n",
    "        t_batch = torch.full((bs,), t, device=device, dtype=torch.long)\n",
    "\n",
    "        # activate the model to predict the noise\n",
    "        noise_pred = model((x_t, t_batch)) if emb is None else model((x_t, t_batch, emb))\n",
    "        \n",
    "        # calculate the new point coordinates\n",
    "        x_t = self.update_rule(x_t, noise_pred, t, shape, device)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "    def predict_x0_from_noise(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_rule(self, x_t, noise_pred, t, shape, device):\n",
    "        # x_t.shape : B x N x F\n",
    "        # noise_pred.shape : B x N x F\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def noisify_sample(self, x0, step):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aebc89-3679-405c-8215-7cc69bcd1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMSparseScheduler(DDPMSchedulerBase):\n",
    "    def __init__(self, beta_min=0.0001, beta_max=0.02, n_steps=1000, pres=1e-8, mode='linear'):\n",
    "        super().__init__(beta_min, beta_max, n_steps, mode)\n",
    "        self.pres = pres\n",
    "    \n",
    "    def sparse_from_pts(self, pts:torch.Tensor, shape):\n",
    "        # Receive a tensor of points and return a SparseTensor \n",
    "\n",
    "        pts = pts.reshape(shape)\n",
    "        # make coordinates positive\n",
    "        coords = pts[:, :, :3]\n",
    "        coords = coords - coords.min(dim=1, keepdim=True)[0]\n",
    "        coords = coords.numpy()\n",
    "\n",
    "        # Unfortunately we need to loop over the batch to apply sparse_quantize \n",
    "        # Also DATA have to be in CPU and coords represented as np.arrays\n",
    "        batch = []\n",
    "        for b in range(shape[0]):\n",
    "\n",
    "            c, indices = sparse_quantize(coords[b], self.pres, return_index=True)\n",
    "            f = pts[b][indices]\n",
    "\n",
    "            batch.append(\n",
    "                {'pc':SparseTensor(coords = torch.tensor(c), feats=f)}\n",
    "            )\n",
    "        \n",
    "        batch = sparse_collate_fn(batch)['pc']\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def append_prediction(self, preds, x_t):\n",
    "        preds.append(x_t.F.detach().cpu().numpy())\n",
    "    \n",
    "    def create_noise(self, shape, device):\n",
    "        noise = torch.randn(shape)\n",
    "        noise = self.sparse_from_pts(noise, shape).to(device)\n",
    "        return noise\n",
    "\n",
    "    def update_rule(self, x_t, noise_pred, t, shape, device):\n",
    "        \n",
    "        x_t = x_t.F\n",
    "\n",
    "        # predict x0 from noise\n",
    "        x0 = self.predict_x0_from_noise(x_t, noise_pred, t, shape, device)\n",
    "\n",
    "        coef_x0 = self.beta[t] * self.alpha_hat[t-1].sqrt() / (1 - self.alpha_hat[t])\n",
    "        coef_xt = (1 - self.alpha_hat_prev1[t]) * self.alpha[t].sqrt() / (1 - self.alpha_hat[t])\n",
    "\n",
    "        mean = coef_x0 * x0 + coef_xt * noise_pred\n",
    "\n",
    "        variance = torch.exp(0.5 * torch.log(torch.max(self.beta[t] * (1 - self.alpha_hat_prev1[t]) / (1 - self.alpha_hat[t]), torch.full_like(self.beta[t], 1e-8, device=device))))\n",
    "\n",
    "        x_t = mean + variance * torch.randn_like(mean)\n",
    "\n",
    "        return self.sparse_from_pts(x_t.detach().cpu(), shape).to(device)\n",
    "\n",
    "    def predict_x0_from_noise(self, x_t, noise_pred, t, shape, device):\n",
    "        x0 = (1 / self.alpha_hat[t]).sqrt() * x_t - (1 / self.alpha_hat[t] - 1).sqrt() * noise_pred\n",
    "        return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8206089-47e1-4e11-abf7-a2c8fd1c56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = DDPMSparseScheduler(beta_min=0.0001, beta_max=0.01, n_steps=1000, pres=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f1df0-7fa0-4b42-a57d-a6bcbe0de5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = sched.sample(model, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607daec3-d822-4a8e-be59-d5b256e78921",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fd4a7-001b-40e9-9364-b0eb71104d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
